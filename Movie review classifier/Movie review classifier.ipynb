{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00YI_bYSr3Lg"
      },
      "source": [
        "# Text classification from scratch\n",
        "\n",
        "**Authors:** Mark Omernick, Francois Chollet<br>\n",
        "**Date created:** 2019/11/06<br>\n",
        "**Last modified:** 2020/05/17<br>\n",
        "**Description:** Text sentiment classification starting from raw text files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKG-5EX2r3Lk"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This example shows how to do text classification starting from raw text (as\n",
        "a set of text files on disk). We demonstrate the workflow on the IMDB sentiment\n",
        "classification dataset (unprocessed version). We use the `TextVectorization` layer for\n",
        " word splitting & indexing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCOGK-mkr3Ll"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "3WS-dTrTr3Ll"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, AveragePooling1D, Bidirectional, LSTM, Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoJVaGiwr3Ln"
      },
      "source": [
        "## Load the data: IMDB movie review sentiment classification\n",
        "\n",
        "Let's download the data and inspect its structure."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c-N9_VLgr3Ln",
        "outputId": "d8bc3009-7846-4bfa-b6f3-3fb1cee3ffc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  7317k      0  0:00:11  0:00:11 --:--:--  9.8M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPBLF6rqr3Lo"
      },
      "source": [
        "The `aclImdb` folder contains a `train` and `test` subfolder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCClYoBVr3Lo",
        "outputId": "826cc771-dede-4eae-ffa7-6d7a7c03a80e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "imdbEr.txt  imdb.vocab\tREADME\ttest  train\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRcoHyCYr3Lo",
        "outputId": "0c619834-a92b-43a6-b6ee-4b0ca2668c82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuiJd2UQr3Lp",
        "outputId": "12697f70-3753-4c80-f614-d6367f46f7f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labeledBow.feat  pos\tunsupBow.feat  urls_pos.txt\n",
            "neg\t\t unsup\turls_neg.txt   urls_unsup.txt\n"
          ]
        }
      ],
      "source": [
        "!ls aclImdb/train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dOmRvn8r3Lp"
      },
      "source": [
        "The `aclImdb/train/pos` and `aclImdb/train/neg` folders contain text files, each of\n",
        " which represents one review (either positive or negative):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JVxBQN4r3Lp",
        "outputId": "7e3d3c04-b1b9-4a0c-f15a-96bda3d95b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Being an Austrian myself this has been a straight knock in my face. Fortunately I don't live nowhere near the place where this movie takes place but unfortunately it portrays everything that the rest of Austria hates about Viennese people (or people close to that region). And it is very easy to read that this is exactly the directors intention: to let your head sink into your hands and say \"Oh my god, how can THAT be possible!\". No, not with me, the (in my opinion) totally exaggerated uncensored swinger club scene is not necessary, I watch porn, sure, but in this context I was rather disgusted than put in the right context.<br /><br />This movie tells a story about how misled people who suffer from lack of education or bad company try to survive and live in a world of redundancy and boring horizons. A girl who is treated like a whore by her super-jealous boyfriend (and still keeps coming back), a female teacher who discovers her masochism by putting the life of her super-cruel \"lover\" on the line, an old couple who has an almost mathematical daily cycle (she is the \"official replacement\" of his ex wife), a couple that has just divorced and has the ex husband suffer under the acts of his former wife obviously having a relationship with her masseuse and finally a crazy hitchhiker who asks her drivers the most unusual questions and stretches their nerves by just being super-annoying.<br /><br />After having seen it you feel almost nothing. You're not even shocked, sad, depressed or feel like doing anything... Maybe that's why I gave it 7 points, it made me react in a way I never reacted before. If that's good or bad is up to you!"
          ]
        }
      ],
      "source": [
        "!cat aclImdb/train/pos/6248_7.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqUY__02r3Lq"
      },
      "source": [
        "We are only interested in the `pos` and `neg` subfolders, so let's delete the rest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "jkwqvShCr3Lq"
      },
      "outputs": [],
      "source": [
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for dir in range (8):\n",
        "    os.mkdir(f'aclImdb/train/{dir}')"
      ],
      "metadata": {
        "id": "5A8X8CwGRhUe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for dir in range (8):\n",
        "    os.mkdir(f'aclImdb/test/{dir}')\n",
        "!ls aclImdb/test "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Efxio7onR7CQ",
        "outputId": "d214d150-06de-4871-84a4-7c286efafbde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  1  2  3  4  5  6  7\tlabeledBow.feat  neg  pos  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJ9hCWZjr3Lq"
      },
      "source": [
        "You can use the utility `tf.keras.utils.text_dataset_from_directory` to\n",
        "generate a labeled `tf.data.Dataset` object from a set of text files on disk filed\n",
        " into class-specific folders.\n",
        "\n",
        "Let's use it to generate the training, validation, and test datasets. The validation\n",
        "and training datasets are generated from two subsets of the `train` directory, with 20%\n",
        "of samples going to the validation dataset and 80% going to the training dataset.\n",
        "\n",
        "Having a validation dataset in addition to the test dataset is useful for tuning\n",
        "hyperparameters, such as the model architecture, for which the test dataset should not\n",
        "be used.\n",
        "\n",
        "Before putting the model out into the real world however, it should be retrained using all\n",
        "available training data (without creating a validation dataset), so its performance is maximized.\n",
        "\n",
        "When using the `validation_split` & `subset` arguments, make sure to either specify a\n",
        "random seed, or to pass `shuffle=False`, so that the validation & training splits you\n",
        "get have no overlap."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'aclImdb/train'\n",
        " \n",
        "for root, dirs, files in os.walk(directory):\n",
        "    if root == 'aclImdb/train/neg' or root== 'aclImdb/train/pos':\n",
        "        for file_ in files:\n",
        "            if 1 <= int(file_[-5]) <= 4:\n",
        "                dir_ = int(file_[-5])-1\n",
        "            elif 7 <= int(file_[-5]) <= 9:\n",
        "                dir_ = int(file_[-5])-3\n",
        "            else:  \n",
        "                dir_ = int(file_[-6:-4])-3\n",
        "\n",
        "            os.rename(''.join([root,'/',file_]), f'aclImdb/train/{dir_}/{file_}')"
      ],
      "metadata": {
        "id": "dCY9hUqti_59"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/neg\n",
        "!rm -r aclImdb/train/pos"
      ],
      "metadata": {
        "id": "oPluEvVQUozn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/train "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30C5Ca3kTeap",
        "outputId": "781372b5-c2d3-4dfb-a2ef-c0129c63c087"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  2  4  6  labeledBow.feat  urls_neg.txt  urls_unsup.txt\n",
            "1  3  5  7  unsupBow.feat    urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directory = 'aclImdb/test'\n",
        " \n",
        "for root, dirs, files in os.walk(directory):\n",
        "    if root == 'aclImdb/test/neg' or root== 'aclImdb/test/pos':\n",
        "        for file_ in files:\n",
        "            if 1 <= int(file_[-5]) <= 4:\n",
        "                dir_ = int(file_[-5])-1\n",
        "            elif 7 <= int(file_[-5]) <= 9:\n",
        "                dir_ = int(file_[-5])-3\n",
        "            else:  \n",
        "                dir_ = int(file_[-6:-4])-3\n",
        "\n",
        "            os.rename(''.join([root,'/',file_]), f'aclImdb/test/{dir_}/{file_}')\n",
        "\n",
        "!rm -r aclImdb/test/neg\n",
        "!rm -r aclImdb/test/pos"
      ],
      "metadata": {
        "id": "heJiLHekVD8_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls aclImdb/test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO2P4FRFVEAj",
        "outputId": "3fcd54c4-291a-47d9-ff75-c88d161724bf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  1  2  3  4  5  6  7\tlabeledBow.feat  urls_neg.txt  urls_pos.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPrukP_qr3Lr",
        "outputId": "f384a69e-1ea6-456f-fa49-81526cf17217"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 8 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 8 classes.\n",
            "Using 5000 files for validation.\n",
            "Found 25000 files belonging to 8 classes.\n",
            "Number of batches in raw_train_ds: 625\n",
            "Number of batches in raw_val_ds: 157\n",
            "Number of batches in raw_test_ds: 782\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_val_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        ")\n",
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size)\n",
        "\n",
        "print(f\"Number of batches in raw_train_ds: {raw_train_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_val_ds: {raw_val_ds.cardinality()}\")\n",
        "print(f\"Number of batches in raw_test_ds: {raw_test_ds.cardinality()}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, label in enumerate(raw_train_ds.class_names):\n",
        "  print(\"Label\", i, \"corresponds to\", label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_-tCO-gE0yL",
        "outputId": "e1437900-8f3a-4421-866d-a2b6dc1f0e98"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to 0\n",
            "Label 1 corresponds to 1\n",
            "Label 2 corresponds to 2\n",
            "Label 3 corresponds to 3\n",
            "Label 4 corresponds to 4\n",
            "Label 5 corresponds to 5\n",
            "Label 6 corresponds to 6\n",
            "Label 7 corresponds to 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zHKfpjEr3Lr"
      },
      "source": [
        "Let's preview a few samples:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqR1cFg5r3Lr",
        "outputId": "61348bb5-16ff-45e4-f604-fb1ccf52c4f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'I watched it subtitled as it was in Russian, but really enjoyed it. The main character Sasha was born cursed, with a deadly weapon as an extension of his body. He lived his whole life unhappy because he was different and because anger caused him to do deadly things. <br /><br />When Sasha finally found love in a young woman named Katya everyone tried to take her away from him ending in a deadly battle. There was a fair amount of gore, but not too much for the weak stomached.<br /><br />Not for people who like the regular old Hollywood movie, but for those who enjoy independent films. Kinda got the feeling of an Asian fantasy film.'\n",
            "5\n",
            "b'I have this movie on DVD and must have watched it thirty times by now. I must really love it, right? Well, not really.<br /><br />I was a surfer earlier in my life, and I loved the sport. To this day, I am fascinated by good surfing. Riding Giants has plenty of that, and thus I am a sucker for the thing. But I definitely have some bones to pick with it. (Peralta, you listening?).<br /><br />First, the movie has too little faith in its subject matter. The cutting and editing of the waves is such that the majority of them are sort of ruined. Very, very few waves are actually shown ridden from start to finish. Peralta seems addicted to a hyper kinetic, cut-and-pace method. It gets especially bad in the middle section on the spot Mavericks in Northern California. Not a single wave is ridden start to finish. Almost the entire section on Mavericks (one third of the movie) is a jarring montage of clips with an equally jarring soundtrack. I can understand the effect Peralta was trying to achieve with Mavericks, as the place is a truly frightening mix of bone crushing waves in frigid open ocean chop, but he goes way too far. Mavericks is not just a bad acid trip. Waves are actually ridden there, even with great performances. It would have been good to see some of them. If Peralta thinks this is a grand sport (and I am sure he does), then why does he insist on messing with the subject matter so much? At times, the editing reduces the movie to the inscrutable. There is one fast clip in the section on Peahi in Hawaii, which I still cannot understand. Even if I run it on slow motion on DVD, the image is too fast to be decipherable. It must be a couple of frames in length at the max.<br /><br />Second, have the guys who made this thing ever learned about understatement? It is particularly galling to watch the narrated directors\\' version on DVD. These guys sound like two over-the-top valley girls. The same sentiment shows up in the main production. Every thing is always so goddamn \"amazing\" etc. One character in particular is just plain obnoxious -- Sam George, the editor of Surfer Magazine, who is practically peeing in his pants every time he has anything to say. He is a super drag on the movie.<br /><br />There is a tremendous amount of effort that went into this movie. I mean, just to get the old movie shots they have, and also, all of the interviews. The movie is a great story, and I think it is generally captivating entertainment. Thematically it is well laid out, with the three parts centering around Greg Noll, Jeff Clark, and Laird Hamilton respectively. There are some uses of still photography that are phenomenal. In the directors\\' narration, they say it is a new type of 3D technology, and it really works. The three principle characters shine, both in their interviews and in the water. As an athlete, Laird Hamilton is a revelation. He rises to the pinnacle of his sport in a way that I have only seen Michael Jordan do in basketball. And too, the story of his meeting his father is a gem. It really touched me.<br /><br />It is just that the movie could have been so much more. The very last part of the movie, when the credits roll, gives a hint of what it could have been. There are some beautiful panoramic shots of waves with a magnificent soundtrack. (The soundtrack in the rest of the movie is rubbish, though you may like it if you are fan of the modern, frenetic school of rock.) Anyway there\\'s my two cents...'\n",
            "7\n",
            "b'So Mary and Rhoda have aged--who hasn\\'t? I was a teen when Mary premiered, and a \"young adult\" when it left the air. Yes, it was great to see Mary and Rho together, and yes, maybe the film didn\\'t sustain the comedy of the original series, but there were enough moments that recalled the spirit of the series to make this a fitting tribute. Example: the producer who hires Mary and then dictates the idea for a new series about \"old people.\" Isn\\'t this typical of the mentality of present-day Hollywood TV and film \"bean counters?\" This may not be THE MARY TYLER MOORE SHOW at its best--but it\\'s a pretty damned good look back at one of the best shows we grew up with in the 70s.'\n",
            "4\n",
            "b'Ok, I first saw this movie like at 9:00 on Cinemax a few weeks ago and thought it would be award winning, boy was I 180d on that. This movie bit the big one. I mean, the mother of the monsters shows her true form only at the end of the movie. I\\'m going \" That\\'s it? Why doesn\\'t she show it briefly a little bit more earlier in the movie.\" The plot being the mother and son feast on the blood of young women. Wouldn\\'t it be better if they just went on, you know, a killing spree killing like a couple of young women each, then having the sheriff or a cop find out about and get into the old find a way to kill the monsters,save the young woman/women, and have 1 or 2 more people killed in the process? I think it would be a hell of a lot better that way. It also sucks because the son is the main character and he gets killed first. Why not get rid of the mother first? Plus, how does she have that strength at the end of the movie when she starts killing people? She said it herself she was too weak. What the heck was wrong with Stephen this time? I can never, ever dis the acting on any movie by any actor, after all, they try their best. If it weren\\'t for good acting, I\\'d have given this movie a 1/10. 3/10.'\n",
            "2\n",
            "b'\\'\\'Ranma \\xc2\\xbd\" is my favorite anime by Rumiko Takahashi. The woman really knows how to entertain us with a good story, that is not only a comedy, but also an action anime. The main character of the story is Ranma Saotome, a teenager boy who is also an expert in martial arts. Ranma is engaged to Akane because of an arrangement of both fathers, who are great friends and trained together during many years. <br /><br />Akane is the younger and most violent sister of the Tendo\\'s: Kasumi is the oldest and is very sweet and Nabiki is the middle and loves to win money no matter what.<br /><br />Ranma and Akane fight all the time,specially because both have a very bad temper, and when they discover that Ranma becomes a girl when splashed with cold water as well as his father becomes a panda,many new characters and situations starts to happen. They also discover the reason of the transformation: while fighting, Ranma and his father fell in a cursed river. But not only them had this kind of fate...<br /><br />If you watched \\'\\'Ranma 1/2\\'\\' and liked, I would recommend you \\'\\'Inuyasha\\'\\' and \\'\\'Maison Ikkoku\", two other good creations from Rumiko\\'s hands.'\n",
            "5\n"
          ]
        }
      ],
      "source": [
        "for comments, labels in raw_train_ds.take(1):\n",
        "    for i in range(5):\n",
        "        print(comments.numpy()[i])\n",
        "        print(labels.numpy()[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCkHi9C7r3Ls"
      },
      "source": [
        "## Prepare the data\n",
        "\n",
        "In particular, we remove `<br />` tags."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "bVbJSo-sr3Ls"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization\n",
        "import string\n",
        "import re\n",
        "\n",
        "# Having looked at our data above, we see that the raw text contains HTML break\n",
        "# tags of the form '<br />'. These tags will not be removed by the default\n",
        "# standardizer (which doesn't strip HTML). Because of this, we will need to\n",
        "# create a custom standardization function.\n",
        "def custom_standardization(input_data):\n",
        "    lowercase = tf.strings.lower(input_data)\n",
        "    stripped_html = tf.strings.regex_replace(lowercase, \"<br />\", \" \")\n",
        "    return tf.strings.regex_replace(\n",
        "        stripped_html, f\"[{re.escape(string.punctuation)}]\", \"\"\n",
        "    )\n",
        "\n",
        "\n",
        "# Model constants.\n",
        "max_features = 20000\n",
        "embedding_dim = 128\n",
        "sequence_length = 500\n",
        "\n",
        "# Now that we have our custom standardization, we can instantiate our text\n",
        "# vectorization layer. We are using this layer to normalize, split, and map\n",
        "# strings to integers, so we set our 'output_mode' to 'int'.\n",
        "# Note that we're using the default split function,\n",
        "# and the custom standardization defined above.\n",
        "# We also set an explicit maximum sequence length, since the CNNs later in our\n",
        "# model won't support ragged sequences.\n",
        "vectorize_layer = TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=max_features,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=sequence_length,\n",
        ")\n",
        "\n",
        "# Now that the vocab layer has been created, call `adapt` on a text-only\n",
        "# dataset to create the vocabulary. You don't have to batch, but for very large\n",
        "# datasets this means you're not keeping spare copies of the dataset in memory.\n",
        "\n",
        "# Let's make a text-only dataset (no labels):\n",
        "text_ds = raw_train_ds.map(lambda x, y: x)\n",
        "# Let's call `adapt`:\n",
        "vectorize_layer.adapt(text_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63NUxMv_r3Ls"
      },
      "source": [
        "## Two options to vectorize the data\n",
        "\n",
        "There are 2 ways we can use our text vectorization layer:\n",
        "\n",
        "**Option 1: Make it part of the model**, so as to obtain a model that processes raw\n",
        " strings, like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_btvQZyyr3Ls"
      },
      "source": [
        "```python\n",
        "text_input = tf.keras.Input(shape=(1,), dtype=tf.string, name='text')\n",
        "x = vectorize_layer(text_input)\n",
        "x = layers.Embedding(max_features + 1, embedding_dim)(x)\n",
        "...\n",
        "```\n",
        "\n",
        "**Option 2: Apply it to the text dataset** to obtain a dataset of word indices, then\n",
        " feed it into a model that expects integer sequences as inputs.\n",
        "\n",
        "An important difference between the two is that option 2 enables you to do\n",
        "**asynchronous CPU processing and buffering** of your data when training on GPU.\n",
        "So if you're training the model on GPU, you probably want to go with this option to get\n",
        " the best performance. This is what we will do below.\n",
        "\n",
        "If we were to export our model to production, we'd ship a model that accepts raw\n",
        "strings as input, like in the code snippet for option 1 above. This can be done after\n",
        " training. We do this in the last section.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dA1UOemmr3Lt"
      },
      "outputs": [],
      "source": [
        "\n",
        "def vectorize_text(text, label):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    return vectorize_layer(text), label\n",
        "\n",
        "\n",
        "# Vectorize the data.\n",
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_val_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)\n",
        "\n",
        "# Do async prefetching / buffering of the data for best performance on GPU.\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=10)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=10)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMQZ7dLkr3Lt"
      },
      "source": [
        "## Build a model\n",
        "\n",
        "We choose a simple 1D convnet starting with an `Embedding` layer."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "4mWNkJebAaav"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "90KgF_aar3Lt"
      },
      "outputs": [],
      "source": [
        "# A integer input for vocab indices.\n",
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
        "# 'embedding_dim'.\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Conv1D + global max pooling\n",
        "# x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "# x = layers.Conv1D(128, 7, padding=\"valid\", activation=\"relu\", strides=3)(x)\n",
        "x = layers.LSTM(128, return_sequences=True, return_state=False)(x)\n",
        "x = layers.LSTM(256, return_sequences=True, return_state=False)(x)\n",
        "x = layers.GlobalMaxPooling1D()(x)\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "x = layers.Dense(128, activation=\"relu\")(x)\n",
        "#x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "predictions = tf.keras.layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A integer input for vocab indices.\n",
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "# Next, we add a layer to map those vocab indices into a space of dimensionality\n",
        "# 'embedding_dim'.\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Conv1D(filters = 32, kernel_size = 3, padding = 'same', activation = 'relu')(x)\n",
        "x = layers.AveragePooling1D(pool_size = 2)(x)\n",
        "x = layers.Bidirectional(LSTM(200, dropout = 0.5))(x)\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "predictions = tf.keras.layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "TRswSwsh6qui"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "###x = layers.Embedding(129892, 32)(inputs)\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Bidirectional(LSTM(75, dropout = 0.1))(x)\n",
        "predictions = tf.keras.layers.Dense(8, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "8Scntt66AX-Z"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "pscDGuxJ8xSm"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "inputs = tf.keras.Input(shape=(None,), dtype=\"int64\")\n",
        "\n",
        "x = layers.Embedding(max_features, embedding_dim)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "predictions = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, predictions)\n",
        "\n",
        "# Compile the model with binary crossentropy loss and an adam optimizer.\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "03q5qjCshaTL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "R84f9loChYmI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZE2mZPer3Lt"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCF705t4r3Lt",
        "outputId": "7657ec9c-6735-4e1b-b44b-858e9dec9f3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "625/625 [==============================] - 744s 1s/step - loss: 1.9022 - accuracy: 0.2865 - val_loss: 1.7429 - val_accuracy: 0.3446\n",
            "Epoch 2/10\n",
            "625/625 [==============================] - 784s 1s/step - loss: 1.6524 - accuracy: 0.3776 - val_loss: 1.9581 - val_accuracy: 0.2474\n",
            "Epoch 3/10\n",
            "  3/625 [..............................] - ETA: 10:30 - loss: 1.9202 - accuracy: 0.3750"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "\n",
        "# Fit the model using the train and test datasets.\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRis13fMr3Lu"
      },
      "source": [
        "## Evaluate the model on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LzN-q4Jhr3Lu"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_OjCFror3Lu"
      },
      "source": [
        "## Make an end-to-end model\n",
        "\n",
        "If you want to obtain a model capable of processing raw strings, you can simply\n",
        "create a new model (using the weights we just trained):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZI5P-bLr3Lu"
      },
      "outputs": [],
      "source": [
        "# A string input\n",
        "inputs = tf.keras.Input(shape=(1,), dtype=\"string\")\n",
        "# Turn strings into vocab indices\n",
        "indices = vectorize_layer(inputs)\n",
        "# Turn vocab indices into predictions\n",
        "outputs = model(indices)\n",
        "\n",
        "# Our end to end model\n",
        "end_to_end_model = tf.keras.Model(inputs, outputs)\n",
        "end_to_end_model.compile(\n",
        "    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Test it with `raw_test_ds`, which yields raw strings\n",
        "end_to_end_model.evaluate(raw_test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#BERT"
      ],
      "metadata": {
        "id": "OgVP4d-WXMLn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U \"tensorflow-text==2.11.*\""
      ],
      "metadata": {
        "id": "uMj3URH3XM2Y",
        "outputId": "14db26bc-6314-42de-c04d-a2270f75f12f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/5.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m176.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tf-models-official==2.11.0"
      ],
      "metadata": {
        "id": "8_WvyD83XQri",
        "outputId": "c7a792aa-80c7-417f-946c-103164739763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 KB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.4/662.4 KB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.2/38.2 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from official.nlp import optimization  \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')"
      ],
      "metadata": {
        "id": "nM15c8kKXQvN"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = 'small_bert/bert_en_uncased_L-4_H-512_A-8'\n",
        "tfhub_handle_encoder = 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1'\n",
        "tfhub_handle_preprocess = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'"
      ],
      "metadata": {
        "id": "ET6m596xXQyl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess_model = hub.KerasLayer(tfhub_handle_preprocess)"
      ],
      "metadata": {
        "id": "KgDx6QPdXQ18"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_test = ['this is such an amazing movie!']\n",
        "text_preprocessed = bert_preprocess_model(text_test)\n",
        "\n",
        "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
        "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
        "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
        "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
        "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')"
      ],
      "metadata": {
        "id": "Dx2eNHqxXQ5K",
        "outputId": "4a5c5dd7-3373-4e92-916b-aad76091bebf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys       : ['input_mask', 'input_word_ids', 'input_type_ids']\n",
            "Shape      : (1, 128)\n",
            "Word Ids   : [ 101 2023 2003 2107 2019 6429 3185  999  102    0    0    0]\n",
            "Input Mask : [1 1 1 1 1 1 1 1 1 0 0 0]\n",
            "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = hub.KerasLayer(tfhub_handle_encoder)"
      ],
      "metadata": {
        "id": "5ksruaNaXQ8z"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_results = bert_model(text_preprocessed)\n",
        "\n",
        "print(f'Loaded BERT: {tfhub_handle_encoder}')\n",
        "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
        "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
        "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
        "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')"
      ],
      "metadata": {
        "id": "nDUhhbuYX6e4",
        "outputId": "16945bf4-f74c-484f-f469-d95b0da24d11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded BERT: https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\n",
            "Pooled Outputs Shape:(1, 512)\n",
            "Pooled Outputs Values:[ 0.76262873  0.9928099  -0.18611872  0.36673853  0.1523371   0.65504426\n",
            "  0.9681154  -0.94862705  0.00216182 -0.9877732   0.06842728 -0.97630584]\n",
            "Sequence Outputs Shape:(1, 128, 512)\n",
            "Sequence Outputs Values:[[-0.28946307  0.34321266  0.33231518 ...  0.21300897  0.71020764\n",
            "  -0.05771176]\n",
            " [-0.2874206   0.3198098  -0.23018597 ...  0.5845501  -0.21329726\n",
            "   0.72692066]\n",
            " [-0.6615712   0.68876785 -0.8743292  ...  0.10877268 -0.2617322\n",
            "   0.4785534 ]\n",
            " ...\n",
            " [-0.22561154 -0.28925663 -0.07064398 ...  0.47566003  0.8327717\n",
            "   0.40025344]\n",
            " [-0.29824272 -0.27473173 -0.05450511 ...  0.48849759  1.0955356\n",
            "   0.18163322]\n",
            " [-0.44378266  0.00930682  0.07223728 ...  0.17290092  1.1833241\n",
            "   0.07898061]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_classifier_model():\n",
        "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
        "  encoder_inputs = preprocessing_layer(text_input)\n",
        "\n",
        "  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
        "  outputs = encoder(encoder_inputs)\n",
        "  net = outputs['pooled_output']\n",
        "  net = tf.keras.layers.Dropout(0.1)(net)\n",
        "  net = tf.keras.layers.Dense(8, activation=\"softmax\", name='classifier')(net)\n",
        "\n",
        "  return tf.keras.Model(text_input, net)"
      ],
      "metadata": {
        "id": "P7H93TY3X6im"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = build_classifier_model()\n",
        "bert_raw_result = classifier_model(tf.constant(text_test))\n",
        "print(bert_raw_result)"
      ],
      "metadata": {
        "id": "cBVha44lX6nB",
        "outputId": "917de51c-ee0e-44f8-8b80-37cae066dd9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.02913774 0.01134778 0.01559757 0.56673855 0.17262267 0.02213632\n",
            "  0.04480406 0.13761538]], shape=(1, 8), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(classifier_model)"
      ],
      "metadata": {
        "id": "3xva-hUtX6o4",
        "outputId": "aceddea7-483d-441d-8f9e-d8ece0606123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "metrics = tf.metrics.Accuracy()"
      ],
      "metadata": {
        "id": "tNkpR3_4X6rv"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
        "num_train_steps = steps_per_epoch * epochs\n",
        "num_warmup_steps = int(0.1*num_train_steps)\n",
        "\n",
        "init_lr = 3e-5\n",
        "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
        "                                          num_train_steps=num_train_steps,\n",
        "                                          num_warmup_steps=num_warmup_steps,\n",
        "                                          optimizer_type='adamw')"
      ],
      "metadata": {
        "id": "8Z0aE37IX6v6"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.compile(optimizer=optimizer,\n",
        "                         loss='sparse_categorical_crossentropy',\n",
        "                         metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "LzCIS1uPX6z1"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = classifier_model.fit(raw_train_ds,\n",
        "                               validation_data=raw_val_ds,\n",
        "                               epochs=epochs)"
      ],
      "metadata": {
        "id": "46-F6ReRXRAa",
        "outputId": "1ffe4e67-0082-4527-a0d2-b70e86389637",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "625/625 [==============================] - 177s 278ms/step - loss: 1.8351 - accuracy: 0.3092 - val_loss: 1.6220 - val_accuracy: 0.3800\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 170s 273ms/step - loss: 1.5556 - accuracy: 0.3968 - val_loss: 1.5794 - val_accuracy: 0.3982\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 173s 277ms/step - loss: 1.4345 - accuracy: 0.4414 - val_loss: 1.5900 - val_accuracy: 0.3990\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 169s 270ms/step - loss: 1.3263 - accuracy: 0.4830 - val_loss: 1.6098 - val_accuracy: 0.4018\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 169s 271ms/step - loss: 1.2544 - accuracy: 0.5131 - val_loss: 1.6181 - val_accuracy: 0.3994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = classifier_model.evaluate(raw_test_ds)\n",
        "\n",
        "print(f'Loss: {loss}')\n",
        "print(f'Accuracy: {accuracy}')"
      ],
      "metadata": {
        "id": "yz3Y9TM_e_CE",
        "outputId": "d4433098-7451-4577-8977-d336967da2a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 101s 128ms/step - loss: 1.6138 - accuracy: 0.3978\n",
            "Loss: 1.6138099431991577\n",
            "Accuracy: 0.3978399932384491\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "text_classification_from_scratch",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}